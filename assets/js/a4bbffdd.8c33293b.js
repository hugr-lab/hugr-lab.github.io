"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[9224],{7770:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>o,frontMatter:()=>l,metadata:()=>s,toc:()=>h});const s=JSON.parse('{"id":"deployment/caching","title":"Caching","description":"Hugr provides a two-level caching system to improve query performance and reduce database load. The caching system consists of an in-memory L1 cache and an optional distributed L2 cache backed by Redis or Memcached.","source":"@site/docs/7-deployment/2-caching.md","sourceDirName":"7-deployment","slug":"/deployment/caching","permalink":"/docs/deployment/caching","draft":false,"unlisted":false,"editUrl":"https://github.com/hugr-lab/hugr-lab.github.io/docs/7-deployment/2-caching.md","tags":[],"version":"current","lastUpdatedBy":"vgsml","lastUpdatedAt":1762369235000,"sidebarPosition":2,"frontMatter":{"title":"Caching","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Configuration","permalink":"/docs/deployment/config"},"next":{"title":"Building from Source","permalink":"/docs/deployment/building-source"}}');var c=i(4848),r=i(8453);const l={title:"Caching",sidebar_position:2},a="Caching",d={},h=[{value:"Cache Architecture",id:"cache-architecture",level:2},{value:"Cache Configuration",id:"cache-configuration",level:2},{value:"General Cache Settings",id:"general-cache-settings",level:3},{value:"L1 Cache (In-Memory)",id:"l1-cache-in-memory",level:3},{value:"L2 Cache (Distributed)",id:"l2-cache-distributed",level:3},{value:"Redis-Specific Configuration",id:"redis-specific-configuration",level:4},{value:"Configuration Examples",id:"configuration-examples",level:2},{value:"Single Instance with L1 Cache Only",id:"single-instance-with-l1-cache-only",level:3},{value:"Clustered Deployment with Redis",id:"clustered-deployment-with-redis",level:3},{value:"Using Memcached",id:"using-memcached",level:3},{value:"High Availability Redis Cluster",id:"high-availability-redis-cluster",level:3},{value:"Docker Compose Example with Redis",id:"docker-compose-example-with-redis",level:2},{value:"Docker Compose Example with Memcached",id:"docker-compose-example-with-memcached",level:2},{value:"Cache Behavior",id:"cache-behavior",level:2},{value:"Cache Key Generation",id:"cache-key-generation",level:3},{value:"Cache Invalidation",id:"cache-invalidation",level:3},{value:"Cache Warming",id:"cache-warming",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"L1 Cache Sizing",id:"l1-cache-sizing",level:3},{value:"L2 Cache Backend Selection",id:"l2-cache-backend-selection",level:3},{value:"TTL Tuning",id:"ttl-tuning",level:3},{value:"Monitoring Cache Performance",id:"monitoring-cache-performance",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Cache Not Working",id:"cache-not-working",level:3},{value:"High Memory Usage",id:"high-memory-usage",level:3},{value:"Cache Inconsistency",id:"cache-inconsistency",level:3},{value:"Next Steps",id:"next-steps",level:2}];function t(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)(n.header,{children:(0,c.jsx)(n.h1,{id:"caching",children:"Caching"})}),"\n",(0,c.jsx)(n.p,{children:"Hugr provides a two-level caching system to improve query performance and reduce database load. The caching system consists of an in-memory L1 cache and an optional distributed L2 cache backed by Redis or Memcached."}),"\n",(0,c.jsx)(n.h2,{id:"cache-architecture",children:"Cache Architecture"}),"\n",(0,c.jsx)(n.p,{children:"The hugr caching system is designed with two levels:"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"L1 Cache (In-Memory)"})," - Fast local cache stored in the application memory"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"L2 Cache (Distributed)"})," - Shared cache across multiple hugr instances using Redis or Memcached"]}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"This two-level approach provides:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Fast response times with L1 cache hits"}),"\n",(0,c.jsx)(n.li,{children:"Shared cache state across multiple instances with L2 cache"}),"\n",(0,c.jsx)(n.li,{children:"Reduced database load for frequently accessed queries"}),"\n",(0,c.jsx)(n.li,{children:"Improved scalability in clustered deployments"}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"cache-configuration",children:"Cache Configuration"}),"\n",(0,c.jsx)(n.h3,{id:"general-cache-settings",children:"General Cache Settings"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_TTL"})})," - Time-to-live for cached items (applies to both L1 and L2)"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_TTL=5m\n"})}),"\n",(0,c.jsx)(n.p,{children:"This setting affects how long query results remain cached before requiring re-execution"}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"l1-cache-in-memory",children:"L1 Cache (In-Memory)"}),"\n",(0,c.jsx)(n.p,{children:"The L1 cache is a local in-memory cache that provides fast access to frequently used query results."}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L1_ENABLED"})})," - Enable/disable L1 cache (default: ",(0,c.jsx)(n.code,{children:"false"}),")"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L1_ENABLED=true\n"})}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L1_MAX_SIZE"})})," - Maximum memory allocation in MB (default: ",(0,c.jsx)(n.code,{children:"512"}),")"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L1_MAX_SIZE=1024\n"})}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L1_CLEAN_TIME"})})," - Interval for cleaning expired entries (default: ",(0,c.jsx)(n.code,{children:"10m"}),")"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L1_CLEAN_TIME=10m\n"})}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L1_EVICTION_TIME"})})," - Time before entries are eligible for eviction (default: ",(0,c.jsx)(n.code,{children:"30m"}),")"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L1_EVICTION_TIME=30m\n"})}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"l2-cache-distributed",children:"L2 Cache (Distributed)"}),"\n",(0,c.jsx)(n.p,{children:"The L2 cache is an external distributed cache that can be shared across multiple hugr instances. This is particularly useful in clustered deployments."}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L2_ENABLED"})})," - Enable/disable L2 cache (default: ",(0,c.jsx)(n.code,{children:"false"}),")"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L2_ENABLED=true\n"})}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L2_BACKEND"})})," - Cache backend type: ",(0,c.jsx)(n.code,{children:"redis"})," or ",(0,c.jsx)(n.code,{children:"memcached"})]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L2_BACKEND=redis\n"})}),"\n",(0,c.jsx)(n.p,{children:"Redis is recommended for production deployments due to its reliability and feature set"}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L2_ADDRESSES"})})," - Comma-separated list of cache server addresses"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"# Single server\nCACHE_L2_ADDRESSES=redis:6379\n\n# Multiple servers for high availability\nCACHE_L2_ADDRESSES=redis1:6379,redis2:6379,redis3:6379\n"})}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h4,{id:"redis-specific-configuration",children:"Redis-Specific Configuration"}),"\n",(0,c.jsx)(n.p,{children:"When using Redis as the L2 cache backend, you can configure authentication and database selection:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L2_DATABASE"})})," - Redis database number (default: ",(0,c.jsx)(n.code,{children:"0"}),")"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L2_DATABASE=0\n"})}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L2_USERNAME"})})," - Redis username (for Redis 6+ ACL)"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L2_USERNAME=hugr\n"})}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.code,{children:"CACHE_L2_PASSWORD"})})," - Redis password"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"CACHE_L2_PASSWORD=your-redis-password\n"})}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"configuration-examples",children:"Configuration Examples"}),"\n",(0,c.jsx)(n.h3,{id:"single-instance-with-l1-cache-only",children:"Single Instance with L1 Cache Only"}),"\n",(0,c.jsx)(n.p,{children:"For a single hugr instance, you can use L1 cache for improved performance:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"# Enable L1 cache\nCACHE_L1_ENABLED=true\nCACHE_L1_MAX_SIZE=512\nCACHE_TTL=5m\n\n# L2 cache disabled\nCACHE_L2_ENABLED=false\n"})}),"\n",(0,c.jsx)(n.h3,{id:"clustered-deployment-with-redis",children:"Clustered Deployment with Redis"}),"\n",(0,c.jsx)(n.p,{children:"For clustered deployments, use both L1 and L2 caches for optimal performance:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"# L1 Cache (local)\nCACHE_L1_ENABLED=true\nCACHE_L1_MAX_SIZE=512\n\n# L2 Cache (shared Redis)\nCACHE_L2_ENABLED=true\nCACHE_L2_BACKEND=redis\nCACHE_L2_ADDRESSES=redis:6379\nCACHE_L2_PASSWORD=your-redis-password\n\n# Cache TTL\nCACHE_TTL=10m\n"})}),"\n",(0,c.jsx)(n.h3,{id:"using-memcached",children:"Using Memcached"}),"\n",(0,c.jsx)(n.p,{children:"If you prefer Memcached over Redis:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"# L1 Cache\nCACHE_L1_ENABLED=true\nCACHE_L1_MAX_SIZE=512\n\n# L2 Cache (Memcached)\nCACHE_L2_ENABLED=true\nCACHE_L2_BACKEND=memcached\nCACHE_L2_ADDRESSES=memcached:11211\n\n# Cache TTL\nCACHE_TTL=5m\n"})}),"\n",(0,c.jsx)(n.h3,{id:"high-availability-redis-cluster",children:"High Availability Redis Cluster"}),"\n",(0,c.jsx)(n.p,{children:"For production deployments with Redis cluster:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bash",children:"# L1 Cache\nCACHE_L1_ENABLED=true\nCACHE_L1_MAX_SIZE=1024\n\n# L2 Cache (Redis Cluster)\nCACHE_L2_ENABLED=true\nCACHE_L2_BACKEND=redis\nCACHE_L2_ADDRESSES=redis-node-1:6379,redis-node-2:6379,redis-node-3:6379\nCACHE_L2_USERNAME=hugr\nCACHE_L2_PASSWORD=your-redis-password\nCACHE_L2_DATABASE=0\n\n# Cache TTL\nCACHE_TTL=15m\n"})}),"\n",(0,c.jsx)(n.h2,{id:"docker-compose-example-with-redis",children:"Docker Compose Example with Redis"}),"\n",(0,c.jsx)(n.p,{children:"Here's a complete example using Docker Compose with Redis cache:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-yaml",children:'version: \'3.8\'\n\nservices:\n  hugr:\n    image: ghcr.io/hugr-lab/server:latest\n    ports:\n      - "15000:15000"\n    environment:\n      - BIND=:15000\n      - ADMIN_UI=true\n      - CORE_DB_PATH=/data/core.db\n\n      # L1 Cache\n      - CACHE_L1_ENABLED=true\n      - CACHE_L1_MAX_SIZE=512\n\n      # L2 Cache (Redis)\n      - CACHE_L2_ENABLED=true\n      - CACHE_L2_BACKEND=redis\n      - CACHE_L2_ADDRESSES=redis:6379\n      - CACHE_L2_PASSWORD=redis_password\n\n      # Cache TTL\n      - CACHE_TTL=10m\n    volumes:\n      - ./data:/data\n    depends_on:\n      - redis\n\n  redis:\n    image: redis:7-alpine\n    command: redis-server --requirepass redis_password\n    ports:\n      - "6379:6379"\n    volumes:\n      - redis_data:/data\n\nvolumes:\n  redis_data:\n'})}),"\n",(0,c.jsx)(n.h2,{id:"docker-compose-example-with-memcached",children:"Docker Compose Example with Memcached"}),"\n",(0,c.jsx)(n.p,{children:"Alternative example using Memcached:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-yaml",children:'version: \'3.8\'\n\nservices:\n  hugr:\n    image: ghcr.io/hugr-lab/server:latest\n    ports:\n      - "15000:15000"\n    environment:\n      - BIND=:15000\n      - ADMIN_UI=true\n      - CORE_DB_PATH=/data/core.db\n\n      # L1 Cache\n      - CACHE_L1_ENABLED=true\n      - CACHE_L1_MAX_SIZE=512\n\n      # L2 Cache (Memcached)\n      - CACHE_L2_ENABLED=true\n      - CACHE_L2_BACKEND=memcached\n      - CACHE_L2_ADDRESSES=memcached:11211\n\n      # Cache TTL\n      - CACHE_TTL=10m\n    volumes:\n      - ./data:/data\n    depends_on:\n      - memcached\n\n  memcached:\n    image: memcached:1.6-alpine\n    ports:\n      - "11211:11211"\n    command: memcached -m 256\n'})}),"\n",(0,c.jsx)(n.h2,{id:"cache-behavior",children:"Cache Behavior"}),"\n",(0,c.jsx)(n.h3,{id:"cache-key-generation",children:"Cache Key Generation"}),"\n",(0,c.jsx)(n.p,{children:"Hugr automatically generates cache keys based on:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Query structure"}),"\n",(0,c.jsx)(n.li,{children:"Query parameters"}),"\n",(0,c.jsx)(n.li,{children:"User context (when authentication is enabled)"}),"\n",(0,c.jsx)(n.li,{children:"Data source configuration"}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"If the cache key is not explicitly provided, the user role is also included in the key generation"}),"\n",(0,c.jsx)(n.h3,{id:"cache-invalidation",children:"Cache Invalidation"}),"\n",(0,c.jsx)(n.p,{children:"Cache entries are invalidated when:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"TTL expires"}),"\n",(0,c.jsx)(n.li,{children:"Data source schema is reloaded"}),"\n",(0,c.jsx)(n.li,{children:"Manual cache clear is triggered (via GraphQL mutation)"}),"\n",(0,c.jsxs)(n.li,{children:["The ",(0,c.jsx)(n.code,{children:"@invalidate_cache"})," directive is used (see ",(0,c.jsx)(n.a,{href:"/docs/references/directives",children:"Directive Reference"})," for cache directive explanations)"]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"cache-warming",children:"Cache Warming"}),"\n",(0,c.jsx)(n.p,{children:"For frequently accessed queries, you can implement cache warming strategies:"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsx)(n.li,{children:"Execute common queries after server startup"}),"\n",(0,c.jsx)(n.li,{children:"Use scheduled jobs to refresh cache entries before TTL expiration"}),"\n",(0,c.jsx)(n.li,{children:"Pre-load critical data during deployment"}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,c.jsx)(n.h3,{id:"l1-cache-sizing",children:"L1 Cache Sizing"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Small deployments"}),": 256-512 MB"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Medium deployments"}),": 512-1024 MB"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Large deployments"}),": 1024-2048 MB"]}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"Monitor memory usage and adjust based on:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Available system memory"}),"\n",(0,c.jsx)(n.li,{children:"Query result sizes"}),"\n",(0,c.jsx)(n.li,{children:"Cache hit ratio"}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"l2-cache-backend-selection",children:"L2 Cache Backend Selection"}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"Redis"})," is recommended when:"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"You need data persistence"}),"\n",(0,c.jsx)(n.li,{children:"You want to use Redis Cluster for high availability"}),"\n",(0,c.jsx)(n.li,{children:"You need advanced features (transactions, pub/sub)"}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"Memcached"})," is recommended when:"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"You need simple key-value caching"}),"\n",(0,c.jsx)(n.li,{children:"You want slightly better performance for simple operations"}),"\n",(0,c.jsx)(n.li,{children:"You don't need persistence"}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"ttl-tuning",children:"TTL Tuning"}),"\n",(0,c.jsx)(n.p,{children:"Choose TTL based on your data update frequency:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Frequently updated data"}),": 1-5 minutes"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Moderately updated data"}),": 5-15 minutes"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Rarely updated data"}),": 15-60 minutes"]}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"monitoring-cache-performance",children:"Monitoring Cache Performance"}),"\n",(0,c.jsx)(n.p,{children:"Monitor these metrics to optimize cache configuration:"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Cache Hit Ratio"})," - Percentage of requests served from cache"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Cache Memory Usage"})," - Current L1 cache memory consumption"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"L2 Connection Status"})," - Redis/Memcached connectivity"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Average Response Time"})," - Compare cached vs non-cached queries"]}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:["You can query cache statistics through the hugr admin UI or monitoring endpoints (if ",(0,c.jsx)(n.code,{children:"SERVICE_BIND"})," is configured)."]}),"\n",(0,c.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,c.jsx)(n.h3,{id:"cache-not-working",children:"Cache Not Working"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsxs)(n.li,{children:["Verify ",(0,c.jsx)(n.code,{children:"CACHE_L1_ENABLED"})," or ",(0,c.jsx)(n.code,{children:"CACHE_L2_ENABLED"})," is set to ",(0,c.jsx)(n.code,{children:"true"})]}),"\n",(0,c.jsx)(n.li,{children:"Check cache server connectivity (for L2 cache)"}),"\n",(0,c.jsx)(n.li,{children:"Verify authentication credentials for Redis/Memcached"}),"\n",(0,c.jsx)(n.li,{children:"Review logs for cache-related errors"}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"high-memory-usage",children:"High Memory Usage"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsxs)(n.li,{children:["Reduce ",(0,c.jsx)(n.code,{children:"CACHE_L1_MAX_SIZE"})]}),"\n",(0,c.jsxs)(n.li,{children:["Decrease ",(0,c.jsx)(n.code,{children:"CACHE_TTL"})]}),"\n",(0,c.jsxs)(n.li,{children:["Adjust ",(0,c.jsx)(n.code,{children:"CACHE_L1_EVICTION_TIME"})," for more aggressive eviction"]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"cache-inconsistency",children:"Cache Inconsistency"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsxs)(n.li,{children:["Reduce ",(0,c.jsx)(n.code,{children:"CACHE_TTL"})," for frequently updated data"]}),"\n",(0,c.jsx)(n.li,{children:"Implement cache invalidation on data mutations"}),"\n",(0,c.jsx)(n.li,{children:"Use L2 cache to maintain consistency across instances"}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["Learn about ",(0,c.jsx)(n.a,{href:"/docs/deployment/container",children:"Container Deployment"})," with caching enabled"]}),"\n",(0,c.jsxs)(n.li,{children:["Configure ",(0,c.jsx)(n.a,{href:"/docs/deployment/cluster",children:"Cluster Deployment"})," with shared L2 cache"]}),"\n",(0,c.jsxs)(n.li,{children:["Review ",(0,c.jsx)(n.a,{href:"/docs/deployment/config",children:"Configuration"})," for complete environment variable reference"]}),"\n"]})]})}function o(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,c.jsx)(n,{...e,children:(0,c.jsx)(t,{...e})}):t(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var s=i(6540);const c={},r=s.createContext(c);function l(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(c):e.components||c:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);