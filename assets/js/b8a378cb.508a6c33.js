"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[7623],{7312:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"deployment/cluster","title":"Clustered Deployment","description":"Hugr supports clustered deployment for high availability and scalability. In cluster mode, multiple work nodes are coordinated by a management node, providing load balancing across work nodes.","source":"@site/docs/7-deployment/6-cluster.md","sourceDirName":"7-deployment","slug":"/deployment/cluster","permalink":"/docs/deployment/cluster","draft":false,"unlisted":false,"editUrl":"https://github.com/hugr-lab/hugr-lab.github.io/docs/7-deployment/6-cluster.md","tags":[],"version":"current","lastUpdatedBy":"vgsml","lastUpdatedAt":1762369235000,"sidebarPosition":6,"frontMatter":{"title":"Clustered Deployment","sidebar_position":6},"sidebar":"docsSidebar","previous":{"title":"Containerized Deployment","permalink":"/docs/deployment/container"},"next":{"title":"References","permalink":"/docs/category/references"}}');var t=r(4848),i=r(8453);const o={title:"Clustered Deployment",sidebar_position:6},a="Clustered Deployment",l={},c=[{value:"Cluster Architecture",id:"cluster-architecture",level:2},{value:"How Cluster Mode Works",id:"how-cluster-mode-works",level:3},{value:"Cluster Configuration",id:"cluster-configuration",level:2},{value:"Management Node Configuration",id:"management-node-configuration",level:3},{value:"Work Node Configuration",id:"work-node-configuration",level:3},{value:"Important Configuration Notes",id:"important-configuration-notes",level:3},{value:"Roles and Permissions in Cluster Mode",id:"roles-and-permissions-in-cluster-mode",level:3},{value:"Docker Compose Cluster Deployment",id:"docker-compose-cluster-deployment",level:2},{value:"Basic Cluster Setup",id:"basic-cluster-setup",level:3},{value:"Cluster with Load Balancer (NGINX)",id:"cluster-with-load-balancer-nginx",level:3},{value:"Kubernetes Deployment",id:"kubernetes-deployment",level:2},{value:"Basic Kubernetes Architecture",id:"basic-kubernetes-architecture",level:3},{value:"Management Node Deployment",id:"management-node-deployment",level:3},{value:"Worker Node Deployment",id:"worker-node-deployment",level:3},{value:"Ingress Configuration",id:"ingress-configuration",level:3},{value:"Secrets",id:"secrets",level:3},{value:"Scaling Work Nodes",id:"scaling-work-nodes",level:2},{value:"Docker Compose",id:"docker-compose",level:3},{value:"Kubernetes",id:"kubernetes",level:3},{value:"Horizontal Pod Autoscaler",id:"horizontal-pod-autoscaler",level:3},{value:"Cluster Management",id:"cluster-management",level:2},{value:"Cluster Management Operations",id:"cluster-management-operations",level:3},{value:"GraphQL API for Cluster Management",id:"graphql-api-for-cluster-management",level:3},{value:"Query Operations",id:"query-operations",level:4},{value:"Mutation Operations",id:"mutation-operations",level:4},{value:"Data Source Management",id:"data-source-management",level:4},{value:"Object Storage Management",id:"object-storage-management",level:4},{value:"Authentication Configuration in Cluster Mode",id:"authentication-configuration-in-cluster-mode",level:4},{value:"Complete GraphQL API Reference",id:"complete-graphql-api-reference",level:4},{value:"Schema Synchronization",id:"schema-synchronization",level:3},{value:"Node Health Monitoring",id:"node-health-monitoring",level:3},{value:"Adding/Removing Nodes",id:"addingremoving-nodes",level:3},{value:"Docker Compose",id:"docker-compose-1",level:4},{value:"Kubernetes",id:"kubernetes-1",level:4},{value:"Minikube Development Setup",id:"minikube-development-setup",level:2},{value:"High Availability Considerations",id:"high-availability-considerations",level:2},{value:"Database High Availability",id:"database-high-availability",level:3},{value:"Cache High Availability",id:"cache-high-availability",level:3},{value:"Storage High Availability",id:"storage-high-availability",level:3},{value:"Load Balancing",id:"load-balancing",level:3},{value:"Monitoring and Observability",id:"monitoring-and-observability",level:2},{value:"Metrics to Monitor",id:"metrics-to-monitor",level:3},{value:"Logging",id:"logging",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Work Node Not Connecting to Management",id:"work-node-not-connecting-to-management",level:3},{value:"Schema Not Synchronizing",id:"schema-not-synchronizing",level:3},{value:"Uneven Load Distribution",id:"uneven-load-distribution",level:3},{value:"Split Brain Scenarios",id:"split-brain-scenarios",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Example Repositories",id:"example-repositories",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"clustered-deployment",children:"Clustered Deployment"})}),"\n",(0,t.jsx)(n.p,{children:"Hugr supports clustered deployment for high availability and scalability. In cluster mode, multiple work nodes are coordinated by a management node, providing load balancing across work nodes."}),"\n",(0,t.jsx)(n.h2,{id:"cluster-architecture",children:"Cluster Architecture"}),"\n",(0,t.jsx)(n.p,{children:"A hugr cluster consists of:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Management Node"})," - Manages cluster operations, schema synchronization, data sources, object storage, and authentication settings. The management node runs on port 14000 by default and uses gRPC for communication with work nodes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Work Nodes"})," - Handle GraphQL queries and mutations with load balancing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Shared Core Database"})," - PostgreSQL or DuckDB (read-only) accessible by all nodes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Distributed Cache"})," - Optional Redis/Memcached for shared L2 cache"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"how-cluster-mode-works",children:"How Cluster Mode Works"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Load Balancing"}),": GraphQL queries are distributed across work nodes by a load balancer (nginx/HAProxy/Traefik)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GraphQL API"}),": Work nodes provide the GraphQL API (including AdminUI). The management node does NOT expose GraphQL endpoints"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cluster Operations"}),": When a work node receives a cluster operation request (via ",(0,t.jsx)(n.code,{children:"core.cluster"})," module), it communicates with the management node to execute the operation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Schema Synchronization"}),": The management node automatically synchronizes schemas, data sources, and object storage configurations across all work nodes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No Distributed Query Execution"}),": Each work node processes queries independently; there is no distributed query processing across nodes. This means horizontal scaling is achieved by adding more work nodes behind a load balancer"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                         \u2502  Load Balancer  \u2502\n                         \u2502(nginx/HAProxy/  \u2502\n                         \u2502    Traefik)     \u2502\n                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                 \u2502                \u2502                \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502 Work Node 1 \u2502  \u2502 Work Node 2 \u2502  \u2502 Work Node 3 \u2502\n          \u2502  (GraphQL)  \u2502  \u2502  (GraphQL)  \u2502  \u2502  (GraphQL)  \u2502\n          \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2518\n             \u2502       \u2502        \u2502       \u2502        \u2502       \u2502\n             \u2502   \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510   \u2502\n             \u2502   \u2502  HTTP (bidir)  \u2502  HTTP (bidir)  \u2502   \u2502\n             \u2502   \u25bc                \u25bc                \u25bc   \u2502\n             \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n             \u2502   \u2502      Management Node (HTTP)    \u2502   \u2502\n             \u2502   \u2502  (coordinates work nodes via   \u2502   \u2502\n             \u2502   \u2502   bidirectional HTTP calls)    \u2502   \u2502\n             \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n             \u2502                                         \u2502\n         \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\n         \u2502             \u2502          \u2502          \u2502             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502PostgreSQL\u2502   \u2502  Redis  \u2502 \u2502  MinIO  \u2502 \u2502  Data   \u2502 \u2502 OIDC IdP \u2502\n    \u2502(Core DB) \u2502   \u2502 (Cache) \u2502 \u2502(Storage)\u2502 \u2502 Sources \u2502 \u2502(optional)\u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Architecture Notes:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Work nodes communicate directly with core database (PostgreSQL), Redis, MinIO, and data sources"}),"\n",(0,t.jsxs)(n.li,{children:["Work nodes and management node communicate via ",(0,t.jsx)(n.strong,{children:"bidirectional HTTP"}),":","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["When a work node receives a ",(0,t.jsx)(n.code,{children:"core.cluster"})," GraphQL query, it makes an HTTP request to the management node"]}),"\n",(0,t.jsx)(n.li,{children:"The management node then makes HTTP requests to all work nodes to coordinate cluster operations"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"The management node performs operations across all nodes in the cluster and collects information about their configurations"}),"\n",(0,t.jsx)(n.li,{children:"You can add an OIDC Identity Provider (IdP) to the architecture that work nodes communicate with for authentication"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"cluster-configuration",children:"Cluster Configuration"}),"\n",(0,t.jsx)(n.h3,{id:"management-node-configuration",children:"Management Node Configuration"}),"\n",(0,t.jsx)(n.p,{children:"The management node requires the following environment variables:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Management node binding\nBIND=:14000\n\n# Cluster authentication (shared with work nodes)\nCLUSTER_SECRET=your-cluster-secret\n\n# Node communication timeout\nTIMEOUT=30s\n\n# Node health check interval\nCHECK=1m\n\n# Authentication settings (distributed to work nodes)\nALLOWED_ANONYMOUS=true\nANONYMOUS_ROLE=anonymous\nSECRET_KEY=your-secret-key\nAUTH_CONFIG_FILE=/config/auth.yaml\n\n# OIDC Integration (optional)\nOIDC_ISSUER=https://accounts.google.com\nOIDC_CLIENT_ID=your-client-id\nOIDC_COOKIE_NAME=hugr_session\nOIDC_USERNAME_CLAIM=preferred_username\nOIDC_USERID_CLAIM=sub\nOIDC_ROLE_CLAIM=roles\n"})}),"\n",(0,t.jsxs)(n.p,{children:["For detailed authentication setup instructions, see the ",(0,t.jsx)(n.a,{href:"/docs/deployment/auth",children:"Authentication Setup"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Authentication Distribution"}),": The management node distributes these authentication settings to all work nodes when they connect. Work nodes automatically receive and apply the configuration, ensuring consistent authentication across the cluster."]}),"\n",(0,t.jsx)(n.h3,{id:"work-node-configuration",children:"Work Node Configuration"}),"\n",(0,t.jsx)(n.p,{children:"Each work node needs to know about the management node:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Work node binding\nBIND=:15000\n\n# Cluster configuration\nCLUSTER_SECRET=your-cluster-secret\nCLUSTER_MANAGEMENT_URL=http://management:14000\nCLUSTER_NODE_NAME=worker-1\nCLUSTER_NODE_URL=http://worker-1:15000\nCLUSTER_TIMEOUT=5s\n\n# Core database (shared)\nCORE_DB_PATH=postgres://hugr:password@postgres:5432/hugr_core\n\n# Distributed cache (L2)\nCACHE_L2_ENABLED=true\nCACHE_L2_BACKEND=redis\nCACHE_L2_ADDRESSES=redis:6379\nCACHE_L2_PASSWORD=redis_password\n"})}),"\n",(0,t.jsx)(n.h3,{id:"important-configuration-notes",children:"Important Configuration Notes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"CLUSTER_SECRET"})})," must be identical across all nodes for secure communication"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"CLUSTER_NODE_NAME"})})," must be unique for each work node"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"CLUSTER_NODE_URL"})})," should be accessible by the management node"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"CORE_DB_PATH"})})," must point to a shared database:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"PostgreSQL"})," (recommended) - Full read/write support"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"DuckDB"})," - Only in read-only mode (",(0,t.jsx)(n.code,{children:"CORE_DB_READONLY=true"}),"), as DuckDB cannot handle concurrent writes from multiple processes to the same file. DuckDB cannot be used for the core database in write mode for cluster deployments due to its single-writer limitation"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"L2 cache"})," is strongly recommended for cluster deployments to cache role permissions"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"roles-and-permissions-in-cluster-mode",children:"Roles and Permissions in Cluster Mode"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important"}),": Role and permission synchronization is ",(0,t.jsx)(n.strong,{children:"not"})," performed in cluster mode. However:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"All nodes can share a common core database (PostgreSQL or DuckDB in read-only mode)"}),"\n",(0,t.jsx)(n.li,{children:"Role permissions are cached using the standard caching mechanism (L1/L2) with default TTL from cache configuration"}),"\n",(0,t.jsx)(n.li,{children:"Authentication settings are configured on the management node (via environment variables) and automatically distributed to work nodes"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"docker-compose-cluster-deployment",children:"Docker Compose Cluster Deployment"}),"\n",(0,t.jsx)(n.h3,{id:"basic-cluster-setup",children:"Basic Cluster Setup"}),"\n",(0,t.jsx)(n.p,{children:"Here's a basic cluster configuration with two work nodes."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note"}),": Access the cluster GraphQL API through work nodes (ports 15001, 15002), not the management node. The management node (port 14000) does not provide GraphQL endpoints."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'version: \'3.8\'\n\nservices:\n  management:\n    image: ghcr.io/hugr-lab/management:latest\n    ports:\n      - "14000:14000"\n    environment:\n      - BIND=:14000\n      - CLUSTER_SECRET=cluster-secret-key\n      - TIMEOUT=30s\n      - CHECK=1m\n    restart: unless-stopped\n\n  worker-1:\n    image: ghcr.io/hugr-lab/server:latest\n    ports:\n      - "15001:15000"\n    environment:\n      # Server Config\n      - BIND=:15000\n      - ADMIN_UI=true\n\n      # Cluster Config\n      - CLUSTER_SECRET=cluster-secret-key\n      - CLUSTER_MANAGEMENT_URL=http://management:14000\n      - CLUSTER_NODE_NAME=worker-1\n      - CLUSTER_NODE_URL=http://worker-1:15000\n      - CLUSTER_TIMEOUT=5s\n\n      # Core Database\n      - CORE_DB_PATH=postgres://hugr:password@postgres:5432/hugr_core\n\n      # Cache\n      - CACHE_L1_ENABLED=true\n      - CACHE_L1_MAX_SIZE=512\n      - CACHE_L2_ENABLED=true\n      - CACHE_L2_BACKEND=redis\n      - CACHE_L2_ADDRESSES=redis:6379\n      - CACHE_L2_PASSWORD=redis_password\n    volumes:\n      - ./workspace:/workspace\n    depends_on:\n      - management\n      - postgres\n      - redis\n    restart: unless-stopped\n\n  worker-2:\n    image: ghcr.io/hugr-lab/server:latest\n    ports:\n      - "15002:15000"\n    environment:\n      # Server Config\n      - BIND=:15000\n      - ADMIN_UI=true\n\n      # Cluster Config\n      - CLUSTER_SECRET=cluster-secret-key\n      - CLUSTER_MANAGEMENT_URL=http://management:14000\n      - CLUSTER_NODE_NAME=worker-2\n      - CLUSTER_NODE_URL=http://worker-2:15000\n      - CLUSTER_TIMEOUT=5s\n\n      # Core Database\n      - CORE_DB_PATH=postgres://hugr:password@postgres:5432/hugr_core\n\n      # Cache\n      - CACHE_L1_ENABLED=true\n      - CACHE_L1_MAX_SIZE=512\n      - CACHE_L2_ENABLED=true\n      - CACHE_L2_BACKEND=redis\n      - CACHE_L2_ADDRESSES=redis:6379\n      - CACHE_L2_PASSWORD=redis_password\n    volumes:\n      - ./workspace:/workspace\n    depends_on:\n      - management\n      - postgres\n      - redis\n    restart: unless-stopped\n\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=hugr_core\n      - POSTGRES_USER=hugr\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    restart: unless-stopped\n\n  redis:\n    image: redis:7-alpine\n    command: redis-server --requirepass redis_password\n    volumes:\n      - redis_data:/data\n    restart: unless-stopped\n\nvolumes:\n  postgres_data:\n  redis_data:\n'})}),"\n",(0,t.jsx)(n.h3,{id:"cluster-with-load-balancer-nginx",children:"Cluster with Load Balancer (NGINX)"}),"\n",(0,t.jsx)(n.p,{children:"Add NGINX as a load balancer:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'version: \'3.8\'\n\nservices:\n  nginx:\n    image: nginx:alpine\n    ports:\n      - "80:80"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n    depends_on:\n      - worker-1\n      - worker-2\n    restart: unless-stopped\n\n  management:\n    image: ghcr.io/hugr-lab/management:latest\n    ports:\n      - "14000:14000"\n    environment:\n      - BIND=:14000\n      - CLUSTER_SECRET=cluster-secret-key\n      - TIMEOUT=30s\n      - CHECK=1m\n    restart: unless-stopped\n\n  worker-1:\n    image: ghcr.io/hugr-lab/server:latest\n    environment:\n      - BIND=:15000\n      - ADMIN_UI=false\n      - CLUSTER_SECRET=cluster-secret-key\n      - CLUSTER_MANAGEMENT_URL=http://management:14000\n      - CLUSTER_NODE_NAME=worker-1\n      - CLUSTER_NODE_URL=http://worker-1:15000\n      - CLUSTER_TIMEOUT=5s\n      - CORE_DB_PATH=postgres://hugr:password@postgres:5432/hugr_core\n      - CACHE_L1_ENABLED=true\n      - CACHE_L1_MAX_SIZE=512\n      - CACHE_L2_ENABLED=true\n      - CACHE_L2_BACKEND=redis\n      - CACHE_L2_ADDRESSES=redis:6379\n      - CACHE_L2_PASSWORD=redis_password\n    volumes:\n      - ./workspace:/workspace\n    depends_on:\n      - management\n      - postgres\n      - redis\n    restart: unless-stopped\n\n  worker-2:\n    image: ghcr.io/hugr-lab/server:latest\n    environment:\n      - BIND=:15000\n      - ADMIN_UI=false\n      - CLUSTER_SECRET=cluster-secret-key\n      - CLUSTER_MANAGEMENT_URL=http://management:14000\n      - CLUSTER_NODE_NAME=worker-2\n      - CLUSTER_NODE_URL=http://worker-2:15000\n      - CLUSTER_TIMEOUT=5s\n      - CORE_DB_PATH=postgres://hugr:password@postgres:5432/hugr_core\n      - CACHE_L1_ENABLED=true\n      - CACHE_L1_MAX_SIZE=512\n      - CACHE_L2_ENABLED=true\n      - CACHE_L2_BACKEND=redis\n      - CACHE_L2_ADDRESSES=redis:6379\n      - CACHE_L2_PASSWORD=redis_password\n    volumes:\n      - ./workspace:/workspace\n    depends_on:\n      - management\n      - postgres\n      - redis\n    restart: unless-stopped\n\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=hugr_core\n      - POSTGRES_USER=hugr\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    restart: unless-stopped\n\n  redis:\n    image: redis:7-alpine\n    command: redis-server --requirepass redis_password\n    volumes:\n      - redis_data:/data\n    restart: unless-stopped\n\nvolumes:\n  postgres_data:\n  redis_data:\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Create ",(0,t.jsx)(n.code,{children:"nginx.conf"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-nginx",children:'events {\n    worker_connections 1024;\n}\n\nhttp {\n    upstream hugr_cluster {\n        least_conn;\n        server worker-1:15000 max_fails=3 fail_timeout=30s;\n        server worker-2:15000 max_fails=3 fail_timeout=30s;\n    }\n\n    server {\n        listen 80;\n        server_name _;\n\n        location / {\n            proxy_pass http://hugr_cluster;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n\n            # WebSocket support\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection "upgrade";\n\n            # Timeouts\n            proxy_connect_timeout 60s;\n            proxy_send_timeout 60s;\n            proxy_read_timeout 60s;\n        }\n\n        # Health check endpoint\n        location /health {\n            access_log off;\n            return 200 "healthy\\n";\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"kubernetes-deployment",children:"Kubernetes Deployment"}),"\n",(0,t.jsxs)(n.p,{children:["For Kubernetes deployments, the ",(0,t.jsx)(n.a,{href:"https://github.com/hugr-lab/docker",children:"hugr-lab/docker"})," repository provides templates in the ",(0,t.jsx)(n.code,{children:"k8s/cluster"})," directory."]}),"\n",(0,t.jsx)(n.h3,{id:"basic-kubernetes-architecture",children:"Basic Kubernetes Architecture"}),"\n",(0,t.jsx)(n.p,{children:"A Kubernetes deployment typically includes:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Management Node Deployment"})," - Single replica StatefulSet"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Worker Node Deployment"})," - Multi-replica StatefulSet or Deployment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"PostgreSQL StatefulSet"})," - Persistent core database"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Redis Deployment"})," - Distributed cache"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Services"})," - For internal communication"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ingress"})," - For external access"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"management-node-deployment",children:"Management Node Deployment"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hugr-management\n  labels:\n    app: hugr-management\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hugr-management\n  template:\n    metadata:\n      labels:\n        app: hugr-management\n    spec:\n      containers:\n      - name: management\n        image: ghcr.io/hugr-lab/management:latest\n        ports:\n        - containerPort: 14000\n          name: management\n        env:\n        - name: BIND\n          value: ":14000"\n        - name: CLUSTER_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: hugr-cluster-secret\n              key: cluster-secret\n        - name: TIMEOUT\n          value: "30s"\n        - name: CHECK\n          value: "1m"\n        resources:\n          requests:\n            memory: "256Mi"\n            cpu: "250m"\n          limits:\n            memory: "512Mi"\n            cpu: "500m"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: hugr-management\nspec:\n  selector:\n    app: hugr-management\n  ports:\n  - port: 14000\n    targetPort: 14000\n    name: management\n'})}),"\n",(0,t.jsx)(n.h3,{id:"worker-node-deployment",children:"Worker Node Deployment"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hugr-worker\n  labels:\n    app: hugr-worker\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: hugr-worker\n  template:\n    metadata:\n      labels:\n        app: hugr-worker\n    spec:\n      containers:\n      - name: worker\n        image: ghcr.io/hugr-lab/server:latest\n        ports:\n        - containerPort: 15000\n          name: http\n        env:\n        - name: BIND\n          value: ":15000"\n        - name: ADMIN_UI\n          value: "false"\n        - name: CLUSTER_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: hugr-cluster-secret\n              key: cluster-secret\n        - name: CLUSTER_MANAGEMENT_URL\n          value: "http://hugr-management:14000"\n        - name: CLUSTER_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: CLUSTER_NODE_URL\n          value: "http://$(HOSTNAME).hugr-worker:15000"\n        - name: CLUSTER_TIMEOUT\n          value: "5s"\n        - name: CORE_DB_PATH\n          valueFrom:\n            secretKeyRef:\n              name: hugr-db-secret\n              key: connection-string\n        - name: CACHE_L1_ENABLED\n          value: "true"\n        - name: CACHE_L1_MAX_SIZE\n          value: "512"\n        - name: CACHE_L2_ENABLED\n          value: "true"\n        - name: CACHE_L2_BACKEND\n          value: "redis"\n        - name: CACHE_L2_ADDRESSES\n          value: "redis:6379"\n        - name: CACHE_L2_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: password\n        volumeMounts:\n        - name: workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            memory: "2Gi"\n            cpu: "1"\n          limits:\n            memory: "4Gi"\n            cpu: "2"\n        livenessProbe:\n          httpGet:\n            path: /admin\n            port: 15000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /admin\n            port: 15000\n          initialDelaySeconds: 10\n          periodSeconds: 5\n      volumes:\n      - name: workspace\n        persistentVolumeClaim:\n          claimName: hugr-workspace\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: hugr-worker\nspec:\n  selector:\n    app: hugr-worker\n  ports:\n  - port: 15000\n    targetPort: 15000\n    name: http\n  type: ClusterIP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: hugr-worker-headless\nspec:\n  clusterIP: None\n  selector:\n    app: hugr-worker\n  ports:\n  - port: 15000\n    targetPort: 15000\n    name: http\n'})}),"\n",(0,t.jsx)(n.h3,{id:"ingress-configuration",children:"Ingress Configuration"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hugr-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/ssl-redirect: "true"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: hugr.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: hugr-worker\n            port:\n              number: 15000\n  tls:\n  - hosts:\n    - hugr.example.com\n    secretName: hugr-tls-secret\n'})}),"\n",(0,t.jsx)(n.h3,{id:"secrets",children:"Secrets"}),"\n",(0,t.jsx)(n.p,{children:"Create the required secrets:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Cluster secret\nkubectl create secret generic hugr-cluster-secret \\\n  --from-literal=cluster-secret='your-cluster-secret-key'\n\n# Database connection\nkubectl create secret generic hugr-db-secret \\\n  --from-literal=connection-string='postgres://hugr:password@postgres:5432/hugr_core'\n\n# Redis password\nkubectl create secret generic redis-secret \\\n  --from-literal=password='redis-password'\n"})}),"\n",(0,t.jsx)(n.h2,{id:"scaling-work-nodes",children:"Scaling Work Nodes"}),"\n",(0,t.jsx)(n.h3,{id:"docker-compose",children:"Docker Compose"}),"\n",(0,t.jsx)(n.p,{children:"Scale work nodes dynamically:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Scale to 5 worker nodes\ndocker-compose up -d --scale worker=5\n\n# Scale down to 2 worker nodes\ndocker-compose up -d --scale worker=2\n"})}),"\n",(0,t.jsx)(n.h3,{id:"kubernetes",children:"Kubernetes"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Scale deployment\nkubectl scale deployment hugr-worker --replicas=5\n\n# Auto-scaling with HPA\nkubectl autoscale deployment hugr-worker \\\n  --cpu-percent=70 \\\n  --min=3 \\\n  --max=10\n"})}),"\n",(0,t.jsx)(n.h3,{id:"horizontal-pod-autoscaler",children:"Horizontal Pod Autoscaler"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: hugr-worker-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: hugr-worker\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n"})}),"\n",(0,t.jsx)(n.h2,{id:"cluster-management",children:"Cluster Management"}),"\n",(0,t.jsx)(n.h3,{id:"cluster-management-operations",children:"Cluster Management Operations"}),"\n",(0,t.jsxs)(n.p,{children:["In cluster mode, the hugr GraphQL schema is extended with the ",(0,t.jsx)(n.code,{children:"core.cluster"})," module, which provides:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Schema Management"}),": Load/unload data source catalogs across all work nodes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data Source Configuration"}),": Add, update, or remove data sources (via core module)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Object Storage"}),": Register and manage S3/MinIO storage across the cluster"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cluster Monitoring"}),": Monitor work node health and status"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note"}),": Authentication settings are configured via environment variables or configuration files on the management node, not through GraphQL API. The management node automatically distributes these settings to work nodes when they connect."]}),"\n",(0,t.jsx)(n.h3,{id:"graphql-api-for-cluster-management",children:"GraphQL API for Cluster Management"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important"}),": The management node does NOT provide a GraphQL API. All cluster management operations are performed through the ",(0,t.jsx)(n.strong,{children:"work nodes"})," GraphQL API."]}),"\n",(0,t.jsxs)(n.p,{children:["When you execute a query or mutation in the ",(0,t.jsx)(n.code,{children:"core.cluster"})," module:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["You send the GraphQL request to a ",(0,t.jsx)(n.strong,{children:"work node"})," (via standard endpoint ",(0,t.jsx)(n.code,{children:"http://work-node:15000/graphql"})," or AdminUI at ",(0,t.jsx)(n.code,{children:"http://work-node:15000/admin"}),")"]}),"\n",(0,t.jsx)(n.li,{children:"The work node receives the request"}),"\n",(0,t.jsx)(n.li,{children:"The work node automatically communicates with the management node to perform the cluster operation"}),"\n",(0,t.jsx)(n.li,{children:"The work node returns the result"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Access cluster operations"})," through any work node's GraphQL interface or AdminUI."]}),"\n",(0,t.jsxs)(n.p,{children:["All cluster-specific operations are available in the ",(0,t.jsx)(n.code,{children:"core.cluster"})," module with different access paths depending on the operation type."]}),"\n",(0,t.jsx)(n.h4,{id:"query-operations",children:"Query Operations"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"core.cluster"})," module provides query operations through two approaches:"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"1. Direct View Access"})," - ",(0,t.jsx)(n.code,{children:"query { core { cluster { ... } } }"})]}),"\n",(0,t.jsxs)(n.p,{children:["Views can be queried directly without the ",(0,t.jsx)(n.code,{children:"function"})," wrapper:"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Get registered cluster nodes (view):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"query {\n  core {\n    cluster {\n      cluster_nodes {\n        name\n        version\n        url\n        ready\n        last_seen\n        error\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Get registered object storages (view):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"query {\n  core {\n    cluster {\n      registered_storages {\n        node\n        name\n        type\n        scope\n        Parameters\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"2. Function Access"})," - ",(0,t.jsx)(n.code,{children:"query { function { core { cluster { ... } } } }"})]}),"\n",(0,t.jsx)(n.p,{children:"The same data can also be accessed through functions:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Get registered cluster nodes (function):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"query {\n  function {\n    core {\n      cluster {\n        nodes {\n          name\n          version\n          url\n          ready\n          last_seen\n          error\n        }\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Returns: ",(0,t.jsx)(n.code,{children:"[cluster_nodes]"})," - same as view"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Get registered object storages (function):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"query {\n  function {\n    core {\n      cluster {\n        storages {\n          node\n          name\n          type\n          scope\n          Parameters\n        }\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Returns: ",(0,t.jsx)(n.code,{children:"[registered_storages]"})," - same as view"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Get data source status (function only):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:'query {\n  function {\n    core {\n      cluster {\n        data_source_status(name: "your-datasource-name") {\n          node\n          status\n          error\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Returns: ",(0,t.jsx)(n.code,{children:"[cluster_data_source_status]"})," - data source status on each node"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note"}),": ",(0,t.jsx)(n.code,{children:"cluster_nodes"})," and ",(0,t.jsx)(n.code,{children:"registered_storages"})," can be accessed both as views (direct) and through functions. ",(0,t.jsx)(n.code,{children:"data_source_status"})," is only available as a function."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"List data sources (core module):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"query {\n  core {\n    data_sources {\n      name\n      type\n      description\n      prefix\n      path\n      disabled\n      catalogs {\n        name\n        type\n        path\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h4,{id:"mutation-operations",children:"Mutation Operations"}),"\n",(0,t.jsxs)(n.p,{children:["All mutation operations are functions and use the path: ",(0,t.jsx)(n.code,{children:"mutation { function { core { cluster { ... } } } }"})]}),"\n",(0,t.jsx)(n.h4,{id:"data-source-management",children:"Data Source Management"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Load or reload a data source catalog:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:'mutation {\n  function {\n    core {\n      cluster {\n        load_data_source(name: "your-datasource-name") {\n          success\n          message\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"This operation loads or reloads the data source catalog across all cluster nodes."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Unload a data source catalog:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:'mutation {\n  function {\n    core {\n      cluster {\n        unload_data_source(name: "your-datasource-name") {\n          success\n          message\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"This operation unloads the data source catalog from all cluster nodes without deleting the data source configuration."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Add a new data source (core module):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"mutation addDataSource($data: data_sources_mut_input_data!) {\n  core {\n    insert_data_sources(data: $data) {\n      name\n      type\n      description\n      path\n      catalogs {\n        name\n        type\n        path\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:"With variables:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "data": {\n    "name": "analytics",\n    "type": "postgres",\n    "prefix": "an",\n    "description": "Analytics database",\n    "read_only": false,\n    "as_module": true,\n    "path": "postgres://user:password@postgres:5432/analytics",\n    "catalogs": [\n      {\n        "name": "analytics_schema",\n        "type": "uri",\n        "description": "Analytics schema definitions",\n        "path": "/workspace/analytics/schema"\n      }\n    ]\n  }\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["After adding a data source, use ",(0,t.jsx)(n.code,{children:"load_data_source"})," to load it across the cluster."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Update a data source (core module):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"mutation updateDataSource($name: String!, $data: data_sources_mut_data!) {\n  core {\n    update_data_sources(filter: {name: {eq: $name}}, data: $data) {\n      name\n      description\n      path\n      disabled\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Delete a data source (core module):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"mutation deleteDataSource($name: String!) {\n  core {\n    delete_data_sources(filter: {name: {eq: $name}}) {\n      name\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h4,{id:"object-storage-management",children:"Object Storage Management"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Register a new S3/MinIO object storage:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:'mutation {\n  function {\n    core {\n      cluster {\n        register_object_storage(\n          type: "s3"\n          name: "minio-storage"\n          scope: "my-bucket"\n          key: "minioadmin"\n          secret: "minioadmin"\n          region: "us-east-1"\n          endpoint: "http://minio:9000"\n          use_ssl: false\n          url_style: "path"\n          url_compatibility: false\n        ) {\n          success\n          message\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Register object storage with variables:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:"mutation RegisterStorage(\n  $type: String!\n  $name: String!\n  $scope: String!\n  $key: String!\n  $secret: String!\n  $endpoint: String!\n  $region: String\n  $use_ssl: Boolean\n  $url_style: String!\n) {\n  function {\n    core {\n      cluster {\n        register_object_storage(\n          type: $type\n          name: $name\n          scope: $scope\n          key: $key\n          secret: $secret\n          endpoint: $endpoint\n          region: $region\n          use_ssl: $use_ssl\n          url_style: $url_style\n        ) {\n          success\n          message\n        }\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:"With variables:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "type": "s3",\n  "name": "minio-storage",\n  "scope": "my-bucket",\n  "key": "minioadmin",\n  "secret": "minioadmin",\n  "endpoint": "http://minio:9000",\n  "region": "us-east-1",\n  "use_ssl": false,\n  "url_style": "path"\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"type"}),': Type of object storage (e.g., "s3")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"name"}),": Unique name for the storage"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"scope"}),": Bucket name or bucket sub-path"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"key"}),": Access key ID (AWS or S3-compatible)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"secret"}),": Secret access key"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"region"}),": AWS region (optional)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"endpoint"}),": Storage endpoint URL"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"use_ssl"}),": Whether to use HTTPS (default: true)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"url_style"}),': S3 URL style ("path" or "vhost")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"url_compatibility"}),": URL compatibility mode (optional)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"kms_key_id"}),": AWS KMS key for server-side encryption (optional)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"account_id"}),": Cloudflare R2 account ID (optional)"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Unregister object storage:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:'mutation {\n  function {\n    core {\n      cluster {\n        unregister_object_storage(name: "minio-storage") {\n          success\n          message\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"List registered storages (query):"})}),"\n",(0,t.jsxs)(n.p,{children:["See the query operation ",(0,t.jsx)(n.code,{children:"storages"})," above for listing registered object storages across the cluster."]}),"\n",(0,t.jsx)(n.h4,{id:"authentication-configuration-in-cluster-mode",children:"Authentication Configuration in Cluster Mode"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important"}),": Authentication settings in cluster mode are ",(0,t.jsx)(n.strong,{children:"not"})," managed via GraphQL API. Instead:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Configuration on Management Node"}),": Authentication settings are configured on the management node via environment variables or configuration file (same as single-server deployment)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Automatic Distribution"}),": When a work node starts, it automatically receives authentication settings from the management node"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Centralized Management"}),": All work nodes use the same authentication configuration distributed by the management node"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Configure authentication on the management node"})," using environment variables:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Management Node Environment Variables\nALLOWED_ANONYMOUS=false\nANONYMOUS_ROLE=guest\nSECRET_KEY=your-secret-key\nAUTH_CONFIG_FILE=/config/auth.yaml\n\n# OIDC Configuration (optional)\nOIDC_ISSUER=https://accounts.google.com\nOIDC_CLIENT_ID=your-client-id\nOIDC_COOKIE_NAME=hugr_session\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Or via configuration file (",(0,t.jsx)(n.code,{children:"/config/auth.yaml"}),"):"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"authentication:\n  allowed_anonymous: false\n  anonymous_role: guest\n  secret_key: your-secret-key\n\n  # OIDC settings\n  oidc:\n    issuer: https://accounts.google.com\n    client_id: your-client-id\n    cookie_name: hugr_session\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Work nodes automatically receive and apply these settings when they connect to the management node. See ",(0,t.jsx)(n.a,{href:"/docs/deployment/config",children:"Configuration"})," for complete authentication options."]}),"\n",(0,t.jsx)(n.h4,{id:"complete-graphql-api-reference",children:"Complete GraphQL API Reference"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Summary of Cluster Operations:"})}),"\n",(0,t.jsxs)(n.p,{children:["All cluster operations are accessed via work nodes through the ",(0,t.jsx)(n.code,{children:"core.cluster"})," module."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Query Operations - Views"})," (direct access):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Path: ",(0,t.jsx)(n.code,{children:"query { core { cluster { ... } } }"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"cluster_nodes"})," - Get registered cluster nodes (view)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"registered_storages"})," - Get registered object storages (view)"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Query Operations - Functions"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Path: ",(0,t.jsx)(n.code,{children:"query { function { core { cluster { ... } } } }"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"nodes"})," - Get registered cluster nodes (returns ",(0,t.jsx)(n.code,{children:"[cluster_nodes]"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"storages"})," - Get registered object storages (returns ",(0,t.jsx)(n.code,{children:"[registered_storages]"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"data_source_status(name)"})," - Get data source status across nodes (returns ",(0,t.jsx)(n.code,{children:"[cluster_data_source_status]"}),")"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Mutation Operations"})," (via ",(0,t.jsx)(n.code,{children:"function.core.cluster"}),"):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Path: ",(0,t.jsx)(n.code,{children:"mutation { function { core { cluster { ... } } } }"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"load_data_source(name)"})," - Load/reload data source catalog across cluster"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"unload_data_source(name)"})," - Unload data source catalog from cluster"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"register_object_storage(...)"})," - Register new S3/object storage across cluster"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"unregister_object_storage(name)"})," - Unregister object storage from cluster"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Core Module Operations"})," (data source CRUD):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"core.data_sources"})," - List data sources"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"core.insert_data_sources"})," - Add new data source"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"core.update_data_sources"})," - Update data source"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"core.delete_data_sources"})," - Delete data source"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Access Patterns:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Views (direct)"}),": ",(0,t.jsx)(n.code,{children:"query { core { cluster { cluster_nodes, registered_storages } } }"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Query Functions"}),": ",(0,t.jsx)(n.code,{children:"query { function { core { cluster { nodes, storages, data_source_status } } } }"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Mutation Functions"}),": ",(0,t.jsx)(n.code,{children:"mutation { function { core { cluster { load_data_source, ... } } } }"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note"}),": Cluster nodes and storages can be queried in two ways - directly as views or through functions. Both return the same data. Using direct view access is more efficient as it bypasses the function wrapper layer."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Workflow"}),":"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Execute GraphQL requests through any work node's endpoint or AdminUI"}),"\n",(0,t.jsxs)(n.li,{children:["For cluster operations (",(0,t.jsx)(n.code,{children:"core.cluster"}),"), the work node automatically communicates with the management node"]}),"\n",(0,t.jsxs)(n.li,{children:["After modifying data sources via core module operations, use ",(0,t.jsx)(n.code,{children:"load_data_source"})," or ",(0,t.jsx)(n.code,{children:"unload_data_source"})," to apply changes across the cluster"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"schema-synchronization",children:"Schema Synchronization"}),"\n",(0,t.jsx)(n.p,{children:"The management node automatically synchronizes changes across all work nodes:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Schema or data source changes are made via GraphQL mutation through a ",(0,t.jsx)(n.strong,{children:"work node"})," (using ",(0,t.jsx)(n.code,{children:"core.cluster"})," operations)"]}),"\n",(0,t.jsx)(n.li,{children:"The work node communicates with the management node"}),"\n",(0,t.jsx)(n.li,{children:"Management node updates the shared core database"}),"\n",(0,t.jsx)(n.li,{children:"All work nodes are notified to reload their configurations"}),"\n",(0,t.jsx)(n.li,{children:"L2 cache is invalidated across the cluster to ensure consistency"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"node-health-monitoring",children:"Node Health Monitoring"}),"\n",(0,t.jsx)(n.p,{children:"The management node periodically checks work node health:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Health Check Interval"}),": Configured via ",(0,t.jsx)(n.code,{children:"CHECK"})," environment variable"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Timeout"}),": Configured via ",(0,t.jsx)(n.code,{children:"TIMEOUT"})," environment variable"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Failure Handling"}),": Unhealthy nodes are temporarily removed from the cluster"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"addingremoving-nodes",children:"Adding/Removing Nodes"}),"\n",(0,t.jsx)(n.h4,{id:"docker-compose-1",children:"Docker Compose"}),"\n",(0,t.jsxs)(n.p,{children:["Add new work nodes to ",(0,t.jsx)(n.code,{children:"docker-compose.yml"})," and restart:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"docker-compose up -d worker-3\n"})}),"\n",(0,t.jsx)(n.p,{children:"Remove nodes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"docker-compose stop worker-3\ndocker-compose rm -f worker-3\n"})}),"\n",(0,t.jsx)(n.h4,{id:"kubernetes-1",children:"Kubernetes"}),"\n",(0,t.jsx)(n.p,{children:"Scale the deployment:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kubectl scale deployment hugr-worker --replicas=5\n"})}),"\n",(0,t.jsx)(n.h2,{id:"minikube-development-setup",children:"Minikube Development Setup"}),"\n",(0,t.jsxs)(n.p,{children:["For local Kubernetes development with Minikube, see the example configuration in the ",(0,t.jsx)(n.a,{href:"https://github.com/hugr-lab/docker",children:"hugr-lab/docker"})," repository at ",(0,t.jsx)(n.code,{children:"examples/minikube-cluster.md"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Basic Minikube setup:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Start Minikube\nminikube start --cpus=4 --memory=8192\n\n# Enable ingress\nminikube addons enable ingress\n\n# Apply configurations\nkubectl apply -f k8s/cluster/\n\n# Access the service\nminikube service hugr-worker --url\n"})}),"\n",(0,t.jsx)(n.h2,{id:"high-availability-considerations",children:"High Availability Considerations"}),"\n",(0,t.jsx)(n.h3,{id:"database-high-availability",children:"Database High Availability"}),"\n",(0,t.jsx)(n.p,{children:"For the shared core database:"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"PostgreSQL (Recommended for Production)"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use PostgreSQL with replication (streaming or logical)"}),"\n",(0,t.jsx)(n.li,{children:"Configure automatic failover with tools like Patroni or Stolon"}),"\n",(0,t.jsx)(n.li,{children:"Ensure proper backup and recovery procedures"}),"\n",(0,t.jsx)(n.li,{children:"Full read/write support for all cluster operations"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DuckDB (Development/Read-Only)"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Can only be used in read-only mode (",(0,t.jsx)(n.code,{children:"CORE_DB_READONLY=true"}),")"]}),"\n",(0,t.jsx)(n.li,{children:"DuckDB does not support concurrent writes from multiple processes to the same file"}),"\n",(0,t.jsx)(n.li,{children:"Suitable for read-only cluster deployments or development environments"}),"\n",(0,t.jsx)(n.li,{children:"Prepare the database file before starting the cluster"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"cache-high-availability",children:"Cache High Availability"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use Redis Sentinel for automatic failover"}),"\n",(0,t.jsx)(n.li,{children:"Or Redis Cluster for distributed setup"}),"\n",(0,t.jsx)(n.li,{children:"Configure connection retry logic in work nodes"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"storage-high-availability",children:"Storage High Availability"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use replicated storage for persistent volumes"}),"\n",(0,t.jsx)(n.li,{children:"Consider S3-compatible storage for core database"}),"\n",(0,t.jsx)(n.li,{children:"Implement regular backup strategies"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"load-balancing",children:"Load Balancing"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use multiple load balancer instances"}),"\n",(0,t.jsx)(n.li,{children:"Configure health checks on all work nodes"}),"\n",(0,t.jsx)(n.li,{children:"Implement session affinity if needed (though hugr is stateless)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"monitoring-and-observability",children:"Monitoring and Observability"}),"\n",(0,t.jsx)(n.h3,{id:"metrics-to-monitor",children:"Metrics to Monitor"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Work Node Metrics"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Request rate and latency"}),"\n",(0,t.jsx)(n.li,{children:"Query execution time"}),"\n",(0,t.jsx)(n.li,{children:"Cache hit ratio"}),"\n",(0,t.jsx)(n.li,{children:"Memory and CPU usage"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Management Node Metrics"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Active work nodes count"}),"\n",(0,t.jsx)(n.li,{children:"Schema synchronization events"}),"\n",(0,t.jsx)(n.li,{children:"Node health check failures"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Infrastructure Metrics"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Database connection pool usage"}),"\n",(0,t.jsx)(n.li,{children:"Redis memory usage"}),"\n",(0,t.jsx)(n.li,{children:"Network latency between nodes"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"logging",children:"Logging"}),"\n",(0,t.jsx)(n.p,{children:"Configure centralized logging for all cluster components:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'logging:\n  driver: "fluentd"\n  options:\n    fluentd-address: "localhost:24224"\n    tag: "hugr.{{.Name}}"\n'})}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsx)(n.h3,{id:"work-node-not-connecting-to-management",children:"Work Node Not Connecting to Management"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Verify ",(0,t.jsx)(n.code,{children:"CLUSTER_MANAGEMENT_URL"})," is accessible"]}),"\n",(0,t.jsxs)(n.li,{children:["Check ",(0,t.jsx)(n.code,{children:"CLUSTER_SECRET"})," matches on both nodes"]}),"\n",(0,t.jsx)(n.li,{children:"Review network policies in Kubernetes"}),"\n",(0,t.jsx)(n.li,{children:"Check management node logs"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"schema-not-synchronizing",children:"Schema Not Synchronizing"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Verify core database is accessible by all nodes"}),"\n",(0,t.jsxs)(n.li,{children:["Check ",(0,t.jsx)(n.code,{children:"CORE_DB_PATH"})," configuration"]}),"\n",(0,t.jsx)(n.li,{children:"Ensure L2 cache is working properly"}),"\n",(0,t.jsx)(n.li,{children:"Review management node logs for sync events"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"uneven-load-distribution",children:"Uneven Load Distribution"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Check load balancer configuration"}),"\n",(0,t.jsx)(n.li,{children:"Verify all work nodes are healthy"}),"\n",(0,t.jsx)(n.li,{children:"Review resource limits and actual usage"}),"\n",(0,t.jsx)(n.li,{children:"Consider adjusting load balancing algorithm"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"split-brain-scenarios",children:"Split Brain Scenarios"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Ensure proper network segmentation"}),"\n",(0,t.jsx)(n.li,{children:"Configure appropriate timeouts"}),"\n",(0,t.jsx)(n.li,{children:"Use health checks at multiple levels"}),"\n",(0,t.jsx)(n.li,{children:"Implement proper failure detection"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Always use PostgreSQL"})," for the core database in production clusters (DuckDB only supports read-only mode)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Enable L2 cache"})," to cache role permissions and improve performance across nodes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use separate management node"})," - don't combine management and work node roles"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Configure proper resource limits"})," to prevent node starvation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Implement comprehensive monitoring"})," for all cluster components"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use secrets management"})," for sensitive configuration (cluster secrets, database credentials)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Regular backup"})," of core database and configuration"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Test failover scenarios"})," before production deployment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Manage cluster operations through management node"})," - use its GraphQL API for schema updates, data source configuration, and authentication settings"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cache role permissions"})," - configure appropriate TTL for permission caching to balance security and performance"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"example-repositories",children:"Example Repositories"}),"\n",(0,t.jsx)(n.p,{children:"For complete examples and templates:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Docker Repository"}),": ",(0,t.jsx)(n.a,{href:"https://github.com/hugr-lab/docker",children:"https://github.com/hugr-lab/docker"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"compose/example.cluster.docker-compose.yml"})," - Cluster with Docker Compose"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"k8s/cluster/"})," - Kubernetes templates"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"examples/minikube-cluster.md"})," - Minikube development setup"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Review ",(0,t.jsx)(n.a,{href:"/docs/deployment/config",children:"Configuration"})," for detailed environment variables"]}),"\n",(0,t.jsxs)(n.li,{children:["Configure ",(0,t.jsx)(n.a,{href:"/docs/deployment/caching",children:"Caching"})," for optimal cluster performance"]}),"\n",(0,t.jsxs)(n.li,{children:["Set up ",(0,t.jsx)(n.a,{href:"/docs/deployment/auth",children:"Authentication"})," for cluster security"]}),"\n",(0,t.jsx)(n.li,{children:"Implement monitoring and alerting for production clusters"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var s=r(6540);const t={},i=s.createContext(t);function o(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);